{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/Gxy2+ErZAQ8C/nP23lcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yilenpan/quantized_lora/blob/main/Udacity_PEFT_training_GPT2_for_sequence_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary packages"
      ],
      "metadata": {
        "id": "Tr69vADcLPWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8eQlIiO8JBB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers \"datasets==2.15.0\" torch peft numpy bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading DAIR-AI/emotion"
      ],
      "metadata": {
        "id": "eU4jfLvMLSY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# The dair-ai/emotion dataset has three splits\n",
        "splits = [\"train\", \"test\", \"validation\"]\n",
        "\n",
        "data_splits = load_dataset(\"dair-ai/emotion\")\n"
      ],
      "metadata": {
        "id": "j_H0XAGb8YXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split and format data. The inputs for the model have to have certain keywords removed. Only labels, input_ids, and attention_mask can be used. You must also make sure the inputs are pytorch tensors, and flat."
      ],
      "metadata": {
        "id": "03k0QOiDLWHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def preprocess_function(x):\n",
        "    return tokenizer(x['text'], truncation=True, padding=True)\n",
        "\n",
        "\n",
        "def format_dataset(ds):\n",
        "    ds = ds.remove_columns('text')\n",
        "    ds = ds.rename_column('label', 'labels')\n",
        "    ds.set_format('torch', columns=['labels', 'input_ids', 'attention_mask'])\n",
        "    return ds\n",
        "\n",
        "test_split = data_splits[\"test\"].map(preprocess_function)\n",
        "train_split = data_splits[\"train\"].map(preprocess_function)\n",
        "val_split = data_splits[\"validation\"].map(preprocess_function)\n",
        "\n",
        "test_split = format_dataset(test_split)\n",
        "train_split = format_dataset(train_split)\n",
        "val_split = format_dataset(val_split)\n",
        "\n",
        "\n",
        "print(test_split)\n",
        "print(val_split)\n",
        "\n",
        "print(train_split)"
      ],
      "metadata": {
        "id": "RX4tvY9k8eBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Bytes and Bytes to quantize the model. This converts the data type for the weights from a 32bit number to a 4 bit number. Then load the model with the quantization config. This runs the model at lower precision.\n",
        "\n",
        "Because we are doing a classification task, use the AutoModelForSeqenceClassification package. Add a layer to the model that only has 6 outputs. Finally, freeze the model. We only want to train the lora."
      ],
      "metadata": {
        "id": "YpjX0EK_MJFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from peft import prepare_model_for_kbit_training\n",
        "from transformers import AutoModelForSequenceClassification, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "\n",
        "config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "\n",
        "label2id={'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n",
        "id2label={0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"gpt2\",\n",
        "    num_labels=6,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    quantization_config=config,\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "\n",
        "def get_label(output):\n",
        "    logits = outputs.logits\n",
        "    logits = logits.float()\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    return torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "# Testing out the model no training\n",
        "test_row = test_split[0]\n",
        "outputs = model(test_row['input_ids'].view(1, -1))\n",
        "predicted_label = get_label(outputs)\n",
        "print(f\"(predicted label: {predicted_label}, actual label: {test_row['labels']})\")\n",
        "\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSJ-yLXy8h92",
        "outputId": "5abe1645-f23f-499c-8371-ef105b66b3ed"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(predicted label: 5, actual label: 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Lora config, and attach it to the layers in then Attention mechanism. Loras are matricies that are multiplied by the weights in these layers."
      ],
      "metadata": {
        "id": "OaUR154MMggn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16, # Rank\n",
        "    lora_alpha=8,\n",
        "    bias=\"lora_only\",\n",
        "    target_modules=['c_attn', 'c_proj'], #Assign correct layers (see model)\n",
        "    lora_dropout=0.01,\n",
        "    task_type=TaskType.SEQ_CLS # WTF NOT IN THE DOCS!!!!!!\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, config)\n",
        "\n",
        "print(lora_model.print_trainable_parameters())"
      ],
      "metadata": {
        "id": "H4UVMXrZ8qkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the trainer class"
      ],
      "metadata": {
        "id": "A-KZGvMPNH4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).mean()}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./data/gpt2-lora\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=15,\n",
        "    per_device_train_batch_size=50, # Kick this up if we can\n",
        "    per_device_eval_batch_size=50, # Kick this up if we can\n",
        "    learning_rate=2e-5,\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_split,\n",
        "    eval_dataset=test_split,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(test_split)\n",
        "print(test_split[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fllfKGX8uWq",
        "outputId": "49287054-80a2-460e-e014-39089a63e0d3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['labels', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 2000\n",
            "})\n",
            "{'labels': tensor(0), 'input_ids': tensor([  320,  4203,  2138, 36371,   523,   545,   407,   845, 14742,   826,\n",
            "          783]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training, see how well the model does. It does pretty poorly, starting at 11%"
      ],
      "metadata": {
        "id": "c49D6_G-NKsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "_4GiMC2u8wL2",
        "outputId": "8f67c658-7249-4b58-bb7b-4b3e85c7c9da"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 6.337622165679932,\n",
              " 'eval_accuracy': 0.114,\n",
              " 'eval_runtime': 6.7019,\n",
              " 'eval_samples_per_second': 298.421,\n",
              " 'eval_steps_per_second': 2.387}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "DPvmfOHC8zyQ",
        "outputId": "af297777-78e5-4ebf-da9f-d94d71006022"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4800' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4800/4800 34:12, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.617741</td>\n",
              "      <td>0.341000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.548000</td>\n",
              "      <td>1.507627</td>\n",
              "      <td>0.418500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.548000</td>\n",
              "      <td>1.302602</td>\n",
              "      <td>0.521500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.449800</td>\n",
              "      <td>1.118490</td>\n",
              "      <td>0.584000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.163700</td>\n",
              "      <td>0.984033</td>\n",
              "      <td>0.646500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.163700</td>\n",
              "      <td>0.869175</td>\n",
              "      <td>0.703500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.988700</td>\n",
              "      <td>0.738187</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.822200</td>\n",
              "      <td>0.658167</td>\n",
              "      <td>0.781000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.822200</td>\n",
              "      <td>0.615828</td>\n",
              "      <td>0.789500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.733600</td>\n",
              "      <td>0.577483</td>\n",
              "      <td>0.795000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.673500</td>\n",
              "      <td>0.559299</td>\n",
              "      <td>0.805000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.673500</td>\n",
              "      <td>0.538537</td>\n",
              "      <td>0.812000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.652700</td>\n",
              "      <td>0.527674</td>\n",
              "      <td>0.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.652700</td>\n",
              "      <td>0.521845</td>\n",
              "      <td>0.819500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.619300</td>\n",
              "      <td>0.520705</td>\n",
              "      <td>0.819500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4800, training_loss=1.044102252324422, metrics={'train_runtime': 2053.3229, 'train_samples_per_second': 116.884, 'train_steps_per_second': 2.338, 'total_flos': 6576232119091200.0, 'train_loss': 1.044102252324422, 'epoch': 15.0})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model.save_pretrained(\"mygpt2lora\")"
      ],
      "metadata": {
        "id": "xXQWWZid9hsC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vxbipFp0IK8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the old model and evaluated performance\n",
        "trainer.model = model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "xNxwAxnrBmpa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5374ad99-02db-48ab-b1e9-bbbab1093da9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 03:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 6.868651390075684,\n",
              " 'eval_accuracy': 0.1125,\n",
              " 'eval_runtime': 6.3293,\n",
              " 'eval_samples_per_second': 315.991,\n",
              " 'eval_steps_per_second': 6.32,\n",
              " 'epoch': 15.0}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate the lora - 82%!"
      ],
      "metadata": {
        "id": "JiabSbhFNU6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForSequenceClassification\n",
        "\n",
        "reloaded_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
        "    \"mygpt2lora\",\n",
        "    num_labels=6,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    quantization_config=config\n",
        ")\n",
        "\n",
        "trainer.model = reloaded_model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "efzGUHi6G4aq",
        "outputId": "56c08993-efa6-4735-b315-ab9cddf48358"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 07:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.52783203125,\n",
              " 'eval_accuracy': 0.816,\n",
              " 'eval_runtime': 10.3457,\n",
              " 'eval_samples_per_second': 193.316,\n",
              " 'eval_steps_per_second': 3.866,\n",
              " 'epoch': 15.0}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = reloaded_model(test_row['input_ids'].view(1, -1))\n",
        "predicted_label = get_label(outputs)\n",
        "print(f\"(predicted label: {predicted_label}, actual label: {test_row['labels']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQj-6-jyIHRX",
        "outputId": "a4fe2ac2-930e-4f90-c34a-ee807ab98218"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(predicted label: 0, actual label: 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPX8K2g6JICc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}